


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>PyTorch Cheat Sheet &mdash; PyTorch Tutorials 0.4.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.4.1
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_seq2seq_hybrid_frontend_tutorial.html">Deploying a Seq2Seq Model with the Hybrid Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving_loading_models.html">Saving and Loading Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Image</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="finetuning_torchvision_models_tutorial.html">Finetuning Torchvision Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer Using PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a Model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="chatbot_tutorial.html">Chatbot Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a></li>
</ul>
<p class="caption"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating Extensions Using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
</ul>
<p class="caption"><span class="caption-text">Production Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/ONNXLive.html">ONNX Live Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a PyTorch Model in C++</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>PyTorch Cheat Sheet</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/ptcheat.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="pytorch-cheat-sheet">
<h1>PyTorch Cheat Sheet<a class="headerlink" href="#pytorch-cheat-sheet" title="Permalink to this headline">¶</a></h1>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="section" id="general">
<h3>General<a class="headerlink" href="#general" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>                                        <span class="c1"># root package</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Dataloader</span>    <span class="c1"># dataset representation and loading</span>
</pre></div>
</div>
</div>
<div class="section" id="neural-network-api">
<h3>Neural Network API<a class="headerlink" href="#neural-network-api" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.autograd</span> <span class="kn">as</span> <span class="nn">autograd</span>         <span class="c1"># computation graph</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>       <span class="c1"># variable node in computation graph</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>                     <span class="c1"># neural networks</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>           <span class="c1"># layers, activations and more</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>               <span class="c1"># optimizers e.g. gradient descent, ADAM, etc.</span>
<span class="kn">from</span> <span class="nn">torch.jit</span> <span class="kn">import</span> <span class="n">script</span><span class="p">,</span> <span class="n">trace</span>       <span class="c1"># hybrid frontend decorator and tracing jit</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/autograd.html">autograd</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html">nn</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch-nn-functional">functional</a>
and <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">optim</a></p>
</div>
<div class="section" id="hybrid-frontend">
<h3>Hybrid frontend<a class="headerlink" href="#hybrid-frontend" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span>         <span class="c1"># takes your module or function and an example</span>
                          <span class="c1"># data input, and traces the computational steps</span>
                          <span class="c1"># that the data encounters as it progresses through the model</span>

<span class="nd">@script</span>                   <span class="c1"># decorator used to indicate data-dependent</span>
                          <span class="c1"># control flow within the code being traced</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/hybridfrontend">hybrid frontend</a></p>
</div>
<div class="section" id="onnx">
<h3>ONNX<a class="headerlink" href="#onnx" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy</span> <span class="n">data</span><span class="p">,</span> <span class="n">xxxx</span><span class="o">.</span><span class="n">proto</span><span class="p">)</span>       <span class="c1"># exports an ONNX formatted</span>
                                                       <span class="c1"># model using a trained model, dummy</span>
                                                       <span class="c1"># data and the desired file name</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;alexnet.proto&quot;</span><span class="p">)</span>                     <span class="c1"># load an ONNX model</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>                        <span class="c1"># check that the model</span>
                                                       <span class="c1"># IR is well formed</span>

<span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">printable_graph</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>               <span class="c1"># print a human readable</span>
                                                       <span class="c1"># representation of the graph</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">onnx</a></p>
</div>
<div class="section" id="vision">
<h3>Vision<a class="headerlink" href="#vision" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>     <span class="c1"># vision datasets,</span>
                                                         <span class="c1"># architectures &amp;</span>
                                                         <span class="c1"># transforms</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>              <span class="c1"># composable transforms</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/torchvision/index.html">torchvision</a></p>
</div>
<div class="section" id="distributed-training">
<h3>Distributed Training<a class="headerlink" href="#distributed-training" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="kn">as</span> <span class="nn">dist</span>          <span class="c1"># distributed communication</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Process</span>       <span class="c1"># memory sharing processes</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/distributed.html">distributed</a>
and
<a class="reference external" href="https://pytorch.org/docs/stable/multiprocessing.html">multiprocessing</a></p>
</div>
</div>
<div class="section" id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="creation">
<h3>Creation<a class="headerlink" href="#creation" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>              <span class="c1"># tensor with independent N(0,1) entries</span>
<span class="n">torch</span><span class="o">.</span><span class="p">[</span><span class="n">ones</span><span class="o">|</span><span class="n">zeros</span><span class="p">](</span><span class="o">*</span><span class="n">size</span><span class="p">)</span>       <span class="c1"># tensor with all 1&#39;s [or 0&#39;s]</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>                 <span class="c1"># create tensor from [nested] list or ndarray L</span>
<span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>                       <span class="c1"># clone of x</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>           <span class="c1"># code wrap that stops autograd from tracking tensor history</span>
<span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span>              <span class="c1"># arg, when set to True, tracks computation</span>
                                <span class="c1"># history for future derivative calculations</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html">tensor</a></p>
</div>
<div class="section" id="dimensionality">
<h3>Dimensionality<a class="headerlink" href="#dimensionality" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>                              <span class="c1"># return tuple-like object of dimensions</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">tensor_seq</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># concatenates tensors along dim</span>
<span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>                       <span class="c1"># reshapes x into size (a,b,...)</span>
<span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">a</span><span class="p">)</span>                          <span class="c1"># reshapes x into size (b,a) for some b</span>
<span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>                      <span class="c1"># swaps dimensions a and b</span>
<span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">dims</span><span class="p">)</span>                      <span class="c1"># permutes dimensions</span>
<span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>                      <span class="c1"># tensor with added axis</span>
<span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>                    <span class="c1"># (a,b,c) tensor -&gt; (a,b,1,c) tensor</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html">tensor</a></p>
</div>
<div class="section" id="algebra">
<h3>Algebra<a class="headerlink" href="#algebra" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>       <span class="c1"># matrix multiplication</span>
<span class="n">A</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>       <span class="c1"># matrix-vector multiplication</span>
<span class="n">x</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>         <span class="c1"># matrix transpose</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations">math
operations</a></p>
</div>
<div class="section" id="gpu-usage">
<h3>GPU Usage<a class="headerlink" href="#gpu-usage" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span>                                 <span class="c1"># check for cuda</span>
<span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>                                                <span class="c1"># move x&#39;s data from</span>
                                                        <span class="c1"># CPU to GPU and return new object</span>

<span class="n">x</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>                                                 <span class="c1"># move x&#39;s data from GPU to CPU</span>
                                                        <span class="c1"># and return new object</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">disable_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span> <span class="c1"># device agnostic code</span>
    <span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>                  <span class="c1"># and modularity</span>
<span class="k">else</span><span class="p">:</span>                                                   <span class="c1">#</span>
    <span class="n">args</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>                   <span class="c1">#</span>

<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                          <span class="c1"># recursively convert their</span>
                                                        <span class="c1"># parameters and buffers to</span>
                                                        <span class="c1"># device specific tensors</span>

<span class="n">mytensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                                     <span class="c1"># copy your tensors to a device</span>
                                                        <span class="c1"># (gpu, cpu)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/cuda.html">cuda</a></p>
</div>
</div>
<div class="section" id="deep-learning">
<h2>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>                                <span class="c1"># fully connected layer from</span>
                                              <span class="c1"># m to n units</span>

<span class="n">nn</span><span class="o">.</span><span class="n">ConvXd</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">s</span><span class="p">)</span>                              <span class="c1"># X dimensional conv layer from</span>
                                              <span class="c1"># m to n channels where X⍷{1,2,3}</span>
                                              <span class="c1"># and the kernel size is s</span>

<span class="n">nn</span><span class="o">.</span><span class="n">MaxPoolXd</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>                               <span class="c1"># X dimension pooling layer</span>
                                              <span class="c1"># (notation as above)</span>

<span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span>                                  <span class="c1"># batch norm layer</span>
<span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="o">/</span><span class="n">LSTM</span><span class="o">/</span><span class="n">GRU</span>                               <span class="c1"># recurrent layers</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>              <span class="c1"># dropout layer for any dimensional input</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>            <span class="c1"># 2-dimensional channel-wise dropout</span>
<span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>   <span class="c1"># (tensor-wise) mapping from</span>
                                              <span class="c1"># indices to embedding vectors</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html">nn</a></p>
<div class="section" id="loss-functions">
<h3>Loss Functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>       <span class="c1"># BCELoss, CrossEntropyLoss,</span>
                                      <span class="c1"># L1Loss, MSELoss, NLLLoss, SoftMarginLoss,</span>
                                      <span class="c1"># MultiLabelSoftMarginLoss, CosineEmbeddingLoss,</span>
                                      <span class="c1"># KLDivLoss, MarginRankingLoss, HingeEmbeddingLoss</span>
                                      <span class="c1"># or CosineEmbeddingLoss</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#loss-functions">loss
functions</a></p>
</div>
<div class="section" id="activation-functions">
<h3>Activation Functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>       <span class="c1"># ReLU, ReLU6, ELU, SELU, PReLU, LeakyReLU,</span>
                                      <span class="c1"># Threshold, HardTanh, Sigmoid, Tanh,</span>
                                      <span class="c1"># LogSigmoid, Softplus, SoftShrink,</span>
                                      <span class="c1"># Softsign, TanhShrink, Softmin, Softmax,</span>
                                      <span class="c1"># Softmax2d or LogSoftmax</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">activation
functions</a></p>
</div>
<div class="section" id="optimizers">
<h3>Optimizers<a class="headerlink" href="#optimizers" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">x</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">...</span><span class="p">)</span>      <span class="c1"># create optimizer</span>
<span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                                  <span class="c1"># update weights</span>
<span class="n">optim</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="k">for</span> <span class="n">example</span> <span class="n">X</span> <span class="ow">is</span> <span class="o">...</span>          <span class="c1"># SGD, Adadelta, Adagrad, Adam,</span>
                                            <span class="c1"># SparseAdam, Adamax, ASGD,</span>
                                            <span class="c1"># LBFGS, RMSProp or Rprop</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">optimizers</a></p>
</div>
<div class="section" id="learning-rate-scheduling">
<h3>Learning rate scheduling<a class="headerlink" href="#learning-rate-scheduling" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>      <span class="c1"># create lr scheduler</span>
<span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>                        <span class="c1"># update lr at start of epoch</span>
<span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">X</span> <span class="n">where</span> <span class="o">...</span>          <span class="c1"># LambdaLR, StepLR, MultiStepLR,</span>
                                        <span class="c1"># ExponentialLR or ReduceLROnPLateau</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate">learning rate
scheduler</a></p>
</div>
</div>
<div class="section" id="data-utilities">
<h2>Data Utilities<a class="headerlink" href="#data-utilities" title="Permalink to this headline">¶</a></h2>
<div class="section" id="datasets">
<h3>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dataset</span>                    <span class="c1"># abstract class representing dataset</span>
<span class="n">TensorDataset</span>              <span class="c1"># labelled dataset in the form of tensors</span>
<span class="n">Concat</span> <span class="n">Dataset</span>             <span class="c1"># concatenation of Datasets</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset">datasets</a></p>
</div>
<div class="section" id="dataloaders-and-datasamplers">
<h3>Dataloaders and DataSamplers<a class="headerlink" href="#dataloaders-and-datasamplers" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>      <span class="c1"># loads data batches agnostic</span>
                                            <span class="c1"># of structure of individual data points</span>

<span class="n">sampler</span><span class="o">.</span><span class="n">Sampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>                <span class="c1"># abstract class dealing with</span>
                                            <span class="c1"># ways to sample from dataset</span>

<span class="n">sampler</span><span class="o">.</span><span class="n">XSampler</span> <span class="n">where</span> <span class="o">...</span>                  <span class="c1"># Sequential, Random, Subset,</span>
                                            <span class="c1"># WeightedRandom or Distributed</span>
</pre></div>
</div>
<p>See
<a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">dataloader</a></p>
</div>
<div class="section" id="also-see">
<h3>Also see<a class="headerlink" href="#also-see" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute
Blitz</a>
<em>(pytorch.org)</em></li>
<li><a class="reference external" href="https://discuss.pytorch.org/">PyTorch Forums</a>
<em>(discuss.pytorch.org)</em></li>
<li><a class="reference external" href="https://github.com/wkentaro/pytorch-for-numpy-users">PyTorch for Numpy
users</a>
<em>(github.com/wkentaro/pytorch-for-numpy-users)</em></li>
</ul>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">PyTorch Cheat Sheet</a><ul>
<li><a class="reference internal" href="#imports">Imports</a><ul>
<li><a class="reference internal" href="#general">General</a></li>
<li><a class="reference internal" href="#neural-network-api">Neural Network API</a></li>
<li><a class="reference internal" href="#hybrid-frontend">Hybrid frontend</a></li>
<li><a class="reference internal" href="#onnx">ONNX</a></li>
<li><a class="reference internal" href="#vision">Vision</a></li>
<li><a class="reference internal" href="#distributed-training">Distributed Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tensors">Tensors</a><ul>
<li><a class="reference internal" href="#creation">Creation</a></li>
<li><a class="reference internal" href="#dimensionality">Dimensionality</a></li>
<li><a class="reference internal" href="#algebra">Algebra</a></li>
<li><a class="reference internal" href="#gpu-usage">GPU Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deep-learning">Deep Learning</a><ul>
<li><a class="reference internal" href="#loss-functions">Loss Functions</a></li>
<li><a class="reference internal" href="#activation-functions">Activation Functions</a></li>
<li><a class="reference internal" href="#optimizers">Optimizers</a></li>
<li><a class="reference internal" href="#learning-rate-scheduling">Learning rate scheduling</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-utilities">Data Utilities</a><ul>
<li><a class="reference internal" href="#datasets">Datasets</a></li>
<li><a class="reference internal" href="#dataloaders-and-datasamplers">Dataloaders and DataSamplers</a></li>
<li><a class="reference internal" href="#also-see">Also see</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>